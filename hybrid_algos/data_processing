# Step 1: Load the dataset from the provided Excel file
df = pd.read_excel('Updated_FTIR_DFT_AFM_Dataset_with_LineProfile_600.xlsx')

# Prepare the input features and target classes
X = df.drop("Phase (Target)", axis=1).values  # Features
y = df["Phase (Target)"].values  # Target (0, 1, 2)

# One-hot encode the target labels for the CNN
y_onehot = to_categorical(y)

# Step 2: Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)

# Step 3: Standardize the input features for better CNN performance
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reshape the input features for CNN (since it expects 3D input: [samples, timesteps, features])
X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

# Step 4: Build the CNN for feature extraction from the descriptors (FTIR, DFT, AFM)
cnn_model = Sequential()

# Add convolutional layers for feature extraction
cnn_model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))
cnn_model.add(MaxPooling1D(pool_size=2))

cnn_model.add(Conv1D(64, kernel_size=3, activation='relu'))
cnn_model.add(MaxPooling1D(pool_size=2))

# Flatten the output to feed into a dense layer
cnn_model.add(Flatten())

# Dense layer for learning high-level features
cnn_model.add(Dense(128, activation='relu'))

# Add the final output layer for classification (optional for CNN training)
cnn_model.add(Dense(3, activation='softmax'))

# Compile the CNN model with a custom learning rate
cnn_model.compile(optimizer=Adam(learning_rate=0.0001),  # Changed learning rate here
                  loss='categorical_crossentropy', 
                  metrics=['accuracy'])
